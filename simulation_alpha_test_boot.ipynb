{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of alpha test with bootstrap\n",
    "\n",
    "Functions in order\n",
    "\n",
    "   * func main_simulation_MC\n",
    "   * func estimations\n",
    "   * func bootstrap\n",
    "   * func matrix_completion\n",
    "   * func BH_procedure\n",
    "   * func calculate_FDP_FDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "import scipy.stats as stats\n",
    "from scipy.linalg import fractional_matrix_power as mpower\n",
    "\n",
    "from numpy import diag, sqrt, sort, argsort, log, isnan, var, std, nanmean\n",
    "from numpy.random import randn, choice, random\n",
    "from numpy.linalg import norm, inv, lstsq, svd, eig\n",
    "from numpy.matlib import repmat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function for main simulation body\n",
    "\n",
    "def main_simulation_MC (p1, p2, N, T):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This function is the main body of simulation\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "        p1         : p value for first normal dist\n",
    "        p2         : p value for second normal dist\n",
    "        N          : number of funds\n",
    "        T          : number of time points\n",
    "    \n",
    "    Output: \n",
    "        \n",
    "        output     : a dictionary storing all variable values\n",
    "        Result.mat : .mat file storing results\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # import the hfparams.pkl\n",
    "\n",
    "    pkl_file = open('hfparams.pkl', 'rb')\n",
    "    param = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "\n",
    "    Mc     =      1000 # number of MCs\n",
    "    B      =      500  # number of Boostrap samples\n",
    "    K      =      4    # mumber of observed factors\n",
    "    r      =      1    # num of latent factors\n",
    "    KK     =      K+r  # total num factors\n",
    "\n",
    "    G      =      param['factorscov'] # cov of factors\n",
    "\n",
    "    # Initilization\n",
    "    \n",
    "    alpha        = np.zeros([N,Mc])\n",
    "    \n",
    "    test_B1      = np.zeros([N,Mc])\n",
    "    test_BH1     = np.zeros([N,Mc])\n",
    "    \n",
    "    test_B2      = np.zeros([N,Mc])\n",
    "    test_BH2     = np.zeros([N,Mc])\n",
    "\n",
    "    test_B3      = np.zeros([N,Mc])\n",
    "    test_BH3     = np.zeros([N,Mc])\n",
    "\n",
    "    test_B4      = np.zeros([N,Mc])\n",
    "    test_BH4     = np.zeros([N,Mc])\n",
    "\n",
    "    test_B5      = np.zeros([N,Mc])\n",
    "    test_BH5     = np.zeros([N,Mc])\n",
    "    \n",
    "    test_B6      = np.zeros([N,Mc])\n",
    "    test_BH6     = np.zeros([N,Mc])\n",
    "    \n",
    "    alpha_est_B1 = np.zeros([N,Mc])\n",
    "    alpha_est_B2 = np.zeros([N,Mc])\n",
    "    alpha_est_B3 = np.zeros([N,Mc])\n",
    "    alpha_est_B4 = np.zeros([N,Mc])\n",
    "    alpha_est_B5 = np.zeros([N,Mc])\n",
    "    alpha_est_B6 = np.zeros([N,Mc])\n",
    "\n",
    "    se_B1        = np.zeros([N,Mc])\n",
    "    se_B2        = np.zeros([N,Mc])\n",
    "    se_B3        = np.zeros([N,Mc])\n",
    "    se_B4        = np.zeros([N,Mc])\n",
    "    se_B5        = np.zeros([N,Mc])\n",
    "    se_B6        = np.zeros([N,Mc])\n",
    "\n",
    "    p_B1         = np.zeros([N,Mc])\n",
    "    p_B2         = np.zeros([N,Mc])\n",
    "    p_B3         = np.zeros([N,Mc])\n",
    "    p_B4         = np.zeros([N,Mc])\n",
    "    p_B5         = np.zeros([N,Mc])\n",
    "    p_B6         = np.zeros([N,Mc])\n",
    "\n",
    "    FDP_B1       = np.zeros([Mc,1])\n",
    "    FDP_B2       = np.zeros([Mc,1])\n",
    "    FDP_B3       = np.zeros([Mc,1])\n",
    "    FDP_B4       = np.zeros([Mc,1])\n",
    "    FDP_B5       = np.zeros([Mc,1])\n",
    "    FDP_B6       = np.zeros([Mc,1])\n",
    "\n",
    "    FDP_BH1      = np.zeros([Mc,1])\n",
    "    FDP_BH2      = np.zeros([Mc,1])\n",
    "    FDP_BH3      = np.zeros([Mc,1])\n",
    "    FDP_BH4      = np.zeros([Mc,1])\n",
    "    FDP_BH5      = np.zeros([Mc,1])\n",
    "    FDP_BH6      = np.zeros([Mc,1])\n",
    "\n",
    "    FDN_B1       = np.zeros([Mc,1])\n",
    "    FDN_B2       = np.zeros([Mc,1])\n",
    "    FDN_B3       = np.zeros([Mc,1])\n",
    "    FDN_B4       = np.zeros([Mc,1])\n",
    "    FDN_B5       = np.zeros([Mc,1])\n",
    "    FDN_B6       = np.zeros([Mc,1])\n",
    "\n",
    "    FDN_BH1      = np.zeros([Mc,1])\n",
    "    FDN_BH2      = np.zeros([Mc,1])\n",
    "    FDN_BH3      = np.zeros([Mc,1])\n",
    "    FDN_BH4      = np.zeros([Mc,1])\n",
    "    FDN_BH5      = np.zeros([Mc,1])\n",
    "    FDN_BH6      = np.zeros([Mc,1])\n",
    "    \n",
    "    ave_pow_B1   = np.zeros([Mc,1])\n",
    "    ave_pow_B2   = np.zeros([Mc,1])\n",
    "    ave_pow_B3   = np.zeros([Mc,1])\n",
    "    ave_pow_B4   = np.zeros([Mc,1])\n",
    "    ave_pow_B5   = np.zeros([Mc,1])\n",
    "    ave_pow_B6   = np.zeros([Mc,1])\n",
    "    \n",
    "    ave_pow_BH1  = np.zeros([Mc,1])\n",
    "    ave_pow_BH2  = np.zeros([Mc,1])\n",
    "    ave_pow_BH3  = np.zeros([Mc,1])\n",
    "    ave_pow_BH4  = np.zeros([Mc,1])\n",
    "    ave_pow_BH5  = np.zeros([Mc,1])\n",
    "    ave_pow_BH6  = np.zeros([Mc,1])\n",
    "\n",
    "    # missing values\n",
    "\n",
    "\n",
    "    mis      = param['missing_patterns'] \n",
    "    \n",
    "    mis_loc1 = repmat(mis[-1,:],max(T-mis.shape[0],0),1) \n",
    "    \n",
    "    mis_loc  = np.concatenate((mis[(mis.shape[0]-min(240,mis.shape[0])):,:],mis_loc1),axis = 0).T \n",
    "    \n",
    "    \n",
    "    \n",
    "    # get funds with lower na\n",
    "\n",
    "    idN     = np.sum(mis_loc,axis=1).reshape(-1,1) \n",
    "    \n",
    "    [a,b]   = sort(idN,axis=0), argsort(idN, axis=0, kind='stable')  \n",
    "    \n",
    "    b       = b[(a<0.7*T-(KK+1))].reshape(-1,1) \n",
    "        \n",
    "    idX     = choice(range(len(b)),N) \n",
    "    \n",
    "    mis_loc = mis_loc[b[idX].flatten(),:]  \n",
    "     \n",
    "    id1     = choice(range(N),1) \n",
    "     \n",
    "    id2     = np.argwhere(np.sum(mis_loc,axis=0)==N).reshape(1,-1) \n",
    "     \n",
    "    mis_loc[id1,id2] = 0\n",
    "\n",
    "    \n",
    "    \n",
    "    # generate idiosyncratic matrix\n",
    "\n",
    "    idset        = b[idX]  \n",
    "\n",
    "    Sigma_u      = diag((param['Ustd'][idset].flatten())**2) \n",
    "    \n",
    "    beta         = param['beta'][idset.flatten(),:] \n",
    "\n",
    "    \n",
    "    \n",
    "    # start Mc times loop\n",
    "    \n",
    "    for seed in range(Mc): \n",
    "        \n",
    "        gamma       = param['meanfacret']  \n",
    "\n",
    "    # generate alpha, intercept\n",
    "\n",
    "        rr          = random([N,1]) \n",
    "        \n",
    "        x1          = (rr >(1-p2))*(std(param['alpha'])/2*(randn(N,1)) + 2*std(param['alpha'])/2)\n",
    "        \n",
    "        x2          = np.zeros([N,1])\n",
    "        \n",
    "        x3          = (rr<=p1)*(std(param['alpha'])/2*randn(N,1) - 2*std(param['alpha'])/2) \n",
    "\n",
    "        alpha[:,seed] = (x1 + x2 + x3).flatten()\n",
    "         \n",
    "        intercept   = beta @ gamma + alpha[:,seed].reshape(-1,1)\n",
    "\n",
    "\n",
    "    # generate data\n",
    "                                    \n",
    "        print('Currently runing MC # {}'.format(seed), end='\\r', flush = True)\n",
    "\n",
    "        FACTOR    = randn(T,KK) @ (mpower(G,(1/2))) \n",
    "                                    \n",
    "        F         = FACTOR[:,r:] #4\n",
    "        \n",
    "        Flatent   = FACTOR[:,:r] #1\n",
    "\n",
    "        U         = (mpower(Sigma_u,(1/2))) @ randn(N,T) \n",
    "                                    \n",
    "        R         = intercept @ np.ones([1,T]) + beta @ np.concatenate((F, Flatent),axis=1).T + U \n",
    "  \n",
    "        \n",
    "        Rbar           = R - repmat(nanmean(R,axis=1).reshape(-1,1),1,T) \n",
    "                                    \n",
    "        Rbar[isnan(R)] = 0 \n",
    "                                    \n",
    "        [U,S,V]        = svd(Rbar / sqrt(N) / sqrt(T)) \n",
    "                                    \n",
    "        vhat           = sqrt(T) * V[:,:KK].T\n",
    "                                    \n",
    "        betahat        = T**(-1) * Rbar @ vhat.T  \n",
    "       \n",
    "        Ubar           = Rbar - betahat @ vhat  \n",
    "        \n",
    "        Sigma_uhat     = (Ubar @ Ubar.T)/T \n",
    "        \n",
    "        \n",
    "        \n",
    "    # generate R with missing data\n",
    "        \n",
    "        R_mis     = repmat(R, 1, 1)\n",
    "        \n",
    "        R_mis[mis_loc==1] = np.NaN\n",
    "        \n",
    "        Rbar_mis       = R_mis - repmat(nanmean(R_mis,axis=1).reshape(-1,1),1,T) \n",
    "                                    \n",
    "        Rbar_mis[isnan(R_mis)] = 0 \n",
    "                                    \n",
    "        [U,S,V]        = svd(Rbar_mis / sqrt(N) / sqrt(T)) \n",
    "                                    \n",
    "        vhat_mis       = sqrt(T) * V[:,:KK].T\n",
    "                                    \n",
    "        betahat_mis    = T**(-1) * Rbar_mis @ vhat_mis.T  \n",
    "       \n",
    "        Ubar_mis       = Rbar_mis - betahat_mis @ vhat_mis  \n",
    "        \n",
    "        Sigma_uhat_mis = (Ubar_mis @ Ubar_mis.T)/T \n",
    "        \n",
    "\n",
    "    # Estimation tests \n",
    "\n",
    "        # case (a) all observed 5 + 0\n",
    "                                        \n",
    "        #[test_B1[:,seed], test_BH1[:,seed], p_B1[:,seed], alpha_est_B1[:,seed], se_B1[:,seed]] = estimations(R, FACTOR, 0, diag(Sigma_uhat).reshape(-1,1), 0.05, False, B)\n",
    "     \n",
    "        # case (b) observed 4 + 0\n",
    "        \n",
    "        #[test_B2[:,seed], test_BH2[:,seed], p_B2[:,seed], alpha_est_B2[:,seed], se_B2[:,seed]] = estimations(R, F, 0, diag(Sigma_uhat).reshape(-1,1), 0.05, False, B)\n",
    "     \n",
    "        # case (c) all latent 0 + 5\n",
    "        \n",
    "        #[test_B3[:,seed], test_BH3[:,seed], p_B3[:,seed], alpha_est_B3[:,seed], se_B3[:,seed]] = estimations(R, np.zeros([0,0]), KK, diag(Sigma_uhat).reshape(-1,1), 0.05, False, B)\n",
    "     \n",
    "        # case (d) mixed 4 + 1 (BH4: case (e))\n",
    "        \n",
    "        #[test_B4[:,seed], test_BH4[:,seed], p_B4[:,seed], alpha_est_B4[:,seed], se_B4[:,seed]] = estimations(R, F, r, diag(Sigma_uhat).reshape(-1,1), 0.05, False, B)\n",
    "    \n",
    "        # case (f) mixed 4 + 1 (with missing data)\n",
    "        \n",
    "        #[test_B5[:,seed], test_BH5[:,seed], p_B5[:,seed], alpha_est_B5[:,seed], se_B5[:,seed]] = estimations(R_mis, F, r, diag(Sigma_uhat_mis).reshape(-1,1), 0.05, False, B)\n",
    "    \n",
    "        # case (g) mixed 4 + 1 (with missing data + bootstrap) - see next notebook\n",
    "        \n",
    "        [test_B6[:,seed], test_BH6[:,seed], p_B6[:,seed], alpha_est_B6[:,seed]] = estimations(R_mis, F, r, diag(Sigma_uhat_mis).reshape(-1,1), 0.05, True, B)\n",
    "    \n",
    "        \n",
    "     # FDP/FDN Caluculation: FDP: false rej/total rej; FDN: false accept/all accept\n",
    "\n",
    "        #[FDP_B1[seed], FDN_B1[seed], ave_pow_B1[seed]]     =    calculate_FDP_FDN(test_B1[:,seed],alpha[:,seed])\n",
    "        #[FDP_BH1[seed], FDN_BH1[seed], ave_pow_BH1[seed]]  =    calculate_FDP_FDN(test_BH1[:,seed],alpha[:,seed])\n",
    "        #[FDP_B2[seed], FDN_B2[seed], ave_pow_B2[seed]]     =    calculate_FDP_FDN(test_B2[:,seed],alpha[:,seed])\n",
    "        #[FDP_BH2[seed], FDN_BH2[seed], ave_pow_BH2[seed]]  =    calculate_FDP_FDN(test_BH2[:,seed],alpha[:,seed])\n",
    "        #[FDP_B3[seed], FDN_B3[seed], ave_pow_B3[seed]]     =    calculate_FDP_FDN(test_B3[:,seed],alpha[:,seed])\n",
    "        #[FDP_BH3[seed], FDN_BH3[seed], ave_pow_BH3[seed]]  =    calculate_FDP_FDN(test_BH3[:,seed],alpha[:,seed])\n",
    "        #[FDP_B4[seed], FDN_B4[seed], ave_pow_B4[seed]]     =    calculate_FDP_FDN(test_B4[:,seed],alpha[:,seed])\n",
    "        #[FDP_BH4[seed], FDN_BH4[seed], ave_pow_BH4[seed]]  =    calculate_FDP_FDN(test_BH4[:,seed],alpha[:,seed])\n",
    "        #[FDP_B5[seed], FDN_B5[seed], ave_pow_B5[seed]]     =    calculate_FDP_FDN(test_B5[:,seed],alpha[:,seed])\n",
    "        #[FDP_BH5[seed], FDN_BH5[seed], ave_pow_BH5[seed]]  =    calculate_FDP_FDN(test_BH5[:,seed],alpha[:,seed])\n",
    "        [FDP_B6[seed], FDN_B6[seed], ave_pow_B6[seed]]     =    calculate_FDP_FDN(test_B6[:,seed],alpha[:,seed])\n",
    "        [FDP_BH6[seed], FDN_BH6[seed], ave_pow_BH6[seed]]  =    calculate_FDP_FDN(test_BH6[:,seed],alpha[:,seed])\n",
    "    \n",
    "    # output and save\n",
    "    \n",
    "    var_list = main_simulation_MC.__code__.co_varnames\n",
    "    \n",
    "    output   = {}\n",
    "    \n",
    "    for varnames in var_list:\n",
    "        \n",
    "        if varnames not in ['output', 'varnames', 'var_list', 'param', 'pkl_file']:\n",
    "            \n",
    "            output[varnames] = eval(varnames)\n",
    "    \n",
    "    #savemat('py_Results_p1_'+str(p1*10)+'_p2_'+str(p2*10)+'_N_'+str(N)+'_T_'+str(T)+'_MC.mat', output)\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function for multiple estimations\n",
    "\n",
    "def estimations (R_obs, Fo, Kl, sigmau, tau, boot, bootsize):\n",
    "\n",
    "    '''\n",
    "    \n",
    "    This function is to do the estimation of multiple parameters\n",
    "    \n",
    "    N   = number of funds\n",
    "    T   = number of time points\n",
    "    Ko  = number of observed factors\n",
    "\n",
    "    if latent factor only, set Fo=0.\n",
    "    if obser factor only, set Kl=0.\n",
    "\n",
    "    Input: \n",
    "    \n",
    "        R_obs      : returns that may subject to missing, N by T  \n",
    "        Fo         : matrix of observed factors, Ko by T\n",
    "        Kl         : number of latent factors\n",
    "        sigmau     : N by 1\n",
    "        tau        : significance level\n",
    "        boot       : indicator of whether bootstrap, boot = True/False\n",
    "        bootsize   : size of bootstrap if boot == True\n",
    "\n",
    "    Output: \n",
    "    \n",
    "        testB      : testing decisions by BH, 1 = reject, N by 1\n",
    "        testBH     : testing decisions by BH and alpha screening, N by 1\n",
    "        p          : p values, N by 1\n",
    "        alpha2     : alpha estimate, N by 1\n",
    "        se         : standard error, N by 1\n",
    "        \n",
    "        //beta_est   : estimated beta\n",
    "        //factor_est : estimated factors\n",
    "        //lambda_est : estimated risk premia\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # original data estimation\n",
    "\n",
    "    X        = ~isnan(R_obs) \n",
    "    \n",
    "    R_obs[isnan(R_obs)] = 0 \n",
    "    \n",
    "    [N, T]   = R_obs.shape \n",
    "    \n",
    "    aveR_ind = np.sum(R_obs,axis=1).reshape(-1,1)/np.sum(X,axis=1).reshape(-1,1) \n",
    "   \n",
    "    Rbar     = R_obs - aveR_ind @ np.ones([1,T]) \n",
    "        \n",
    "    Fo       = Fo.T \n",
    "    \n",
    "    # get number of observed and latent factors\n",
    "    \n",
    "    if len(Fo) > 0:\n",
    "        \n",
    "        Ko   = len(Fo[:,0]) \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        Ko   = 0\n",
    "    \n",
    "    K        = Ko + Kl # total factors\n",
    "     \n",
    "    if Kl == 0:  # observed only\n",
    "            \n",
    "        betao_est  = np.zeros([N,Ko])  \n",
    "        \n",
    "        Vo         = Fo-np.mean(Fo,axis=1).reshape(-1,1) @ np.ones([1,T]) \n",
    "                \n",
    "        for i in range(N):\n",
    "            \n",
    "            index  = np.argwhere(X[i,:]>0) \n",
    "            \n",
    "            d      = np.sum(X[i,:])  \n",
    "                    \n",
    "            M_xi   = np.eye(d) - np.ones([d,d])/d \n",
    "                \n",
    "            factor = Fo[:,index.flatten()] \n",
    "            \n",
    "            # % As python has no equivalent of \"/\", I use x=B*inv(A) instead. Same for all inv().\n",
    "            \n",
    "            betao_est[i,:] = (R_obs[i,index.flatten()] @ M_xi @ factor.T) @ inv(factor @ M_xi @ factor.T) \n",
    "            \n",
    "        beta_est   = betao_est\n",
    "        \n",
    "        factor_est = Vo\n",
    "        \n",
    "    elif Ko == 0: # latent only\n",
    "\n",
    "        Z          = X*Rbar  \n",
    "        \n",
    "        [betal_est,F_l_est] = matrix_completion(Z, X, Kl, sigmau) \n",
    "               \n",
    "        beta_est   = betal_est\n",
    "        \n",
    "        factor_est = F_l_est \n",
    "        \n",
    "    elif Ko*Kl > 0: # mixed\n",
    "\n",
    "        betao_est  = np.zeros([N,Ko])\n",
    "        \n",
    "        Vo         = Fo-np.mean(Fo,axis=1).reshape(-1,1) @ np.ones([1,T])\n",
    "        \n",
    "        Z          = np.zeros([N,T])\n",
    "        \n",
    "        for i in range(N):\n",
    "            \n",
    "            index  = np.argwhere(X[i,:]>0) \n",
    "            \n",
    "            d      = np.sum(X[i,:])  \n",
    "                    \n",
    "            M_xi   = np.eye(d) - np.ones([d,d])/d\n",
    "                \n",
    "            factor = Fo[:,index.flatten()] \n",
    "            \n",
    "            betao_est[i,:] = (R_obs[i,index.flatten()] @ M_xi @ factor.T) @ inv(factor @ M_xi @ factor.T) \n",
    "            \n",
    "            Z[i,index.flatten()] = (R_obs[i,index.flatten()]-betao_est[i,:] @ factor) @ M_xi \n",
    "        \n",
    "        \n",
    "        [betal_est,F_l_est] = matrix_completion(Z, X, Kl, sigmau)\n",
    "        \n",
    "        beta_est            = np.concatenate((betao_est,betal_est), axis=1) # mix\n",
    "        \n",
    "        factor_est          = np.concatenate((Vo,F_l_est),axis=0) # K by T \n",
    "            \n",
    "     \n",
    "    residual = (Rbar - beta_est @ factor_est) * X \n",
    "      \n",
    "    [temp1,S,temp2]  =  svd(residual / sqrt(N) / sqrt(T))\n",
    "     \n",
    "    eigs             = diag(S**2)\n",
    "  \n",
    "    M_N              = np.eye(N) - np.ones([N,N])/N\n",
    "    \n",
    "    # % package lstsq serves the same function as \"\\\" in matlab (solve Ax=B)\n",
    "    \n",
    "    Pbeta            = lstsq((beta_est.T @ M_N @ beta_est),beta_est.T)[0] @ M_N\n",
    "     \n",
    "    lambda_est       = Pbeta @ aveR_ind  \n",
    "    \n",
    "    alpha_initial    = aveR_ind - beta_est @ lambda_est  \n",
    "    \n",
    "    \n",
    "    # bias\n",
    "        \n",
    "    B2               = np.eye(N)-beta_est @ Pbeta  # needed for debias alpha\n",
    "    \n",
    "    g                = np.zeros([N,1])   # needed for debias alpha\n",
    " \n",
    "    for i in range(N):\n",
    "        \n",
    "        g[i]  =  beta_est[i,:] @ np.mean(factor_est[:,X[i,:]==1],axis=1)\n",
    "    \n",
    "    bias1            = B2 @ g\n",
    "          \n",
    "    # for bias2\n",
    "         \n",
    "    bias2  = np.zeros([N,1])\n",
    "    \n",
    "    if Ko * Kl > 0: # mixed case\n",
    "        \n",
    "        So  = Vo @ Vo.T/T\n",
    "           \n",
    "        Slo = F_l_est @ Vo.T/T\n",
    "           \n",
    "        Ho  = Slo @ inv(So) \n",
    "          \n",
    "        for i in range(N):\n",
    "            \n",
    "            index   = np.argwhere(X[i,:]>0)\n",
    "            \n",
    "            d       = np.sum(X[i,:])\n",
    "            \n",
    "            Soi     = Vo[:,index.flatten()] @ Vo[:,index.flatten()].T / d\n",
    "            \n",
    "            Sloi    = F_l_est[:,index.flatten()] @ Vo[:,index.flatten()].T / d\n",
    "            \n",
    "            Hoi     = Sloi @ inv(Soi)\n",
    "            \n",
    "            bias2[i]= betal_est[i,:] @ (Hoi-Ho) @ lambda_est[:Ko] \n",
    "\n",
    "       \n",
    "    alpha2 = alpha_initial - bias1+bias2  # get the unbiased alpha\n",
    "       \n",
    "        \n",
    "    # if bootstrap\n",
    "    \n",
    "    if boot == True:\n",
    "        \n",
    "        varlists = ['N','T','K','beta_est','lambda_est','residual', \n",
    "                    'aveR_ind','M_N','factor_est','X','alpha2'] \n",
    "        \n",
    "        vardict = {}\n",
    "        \n",
    "        for varname in varlists:\n",
    "            \n",
    "            vardict[varname] = eval(varname)\n",
    "        \n",
    "        p = bootstrap(vardict, bootsize)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # se \n",
    "\n",
    "        variance_alpha = diag(beta_est @ inv(beta_est.T @ M_N @ beta_est) \n",
    "                               @ beta_est.T * var(alpha_initial)).reshape(-1,1)  \n",
    "\n",
    "        S_f            = factor_est @ factor_est.T / T \n",
    "\n",
    "        var1           = np.zeros([N,1])\n",
    "\n",
    "        for i in range(N):\n",
    "\n",
    "            index      = np.argwhere(X[i,:] > 0)\n",
    "\n",
    "            d          = np.sum(X[i,:])\n",
    "\n",
    "            su         = residual[i,index.flatten()] @ residual[i,index.flatten()].T / d \n",
    "\n",
    "            var1[i]    = su * norm(1 - lambda_est.T @ inv(S_f) @ factor_est[:,index.flatten()]) ** 2 / (d ** 2)  \n",
    "\n",
    "        se             = sqrt(var1 + variance_alpha)\n",
    "\n",
    "        p              = 1 - stats.norm.cdf(alpha2 / se) # get the p values\n",
    "\n",
    "    \n",
    "    # BH\n",
    "    \n",
    "    [testBt, testBHt] = BH_procedure(p, N, T, tau)\n",
    "    \n",
    "    if boot == True:\n",
    "        \n",
    "        return testBt.flatten(), testBHt.flatten(), p.flatten(), alpha2.flatten()\n",
    "\n",
    "    else:\n",
    "        \n",
    "        return testBt.flatten(), testBHt.flatten(), p.flatten(), alpha2.flatten(), se.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function for wild bootstrap\n",
    "\n",
    "def bootstrap (varstore, size):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This function is to do the wild bootstrap\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "        varstore : a dictionary storing vars in function 'estimations'\n",
    "        size     : bootstrap size\n",
    "        \n",
    "    Output:\n",
    "    \n",
    "        p        : p values generated from bootstrap, N by 1\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # load the vars \n",
    "    \n",
    "    N = varstore['N']\n",
    "    T = varstore['T']\n",
    "    K = varstore['K']\n",
    "\n",
    "    beta_est   = varstore['beta_est'] \n",
    "    lambda_est = varstore['lambda_est'] \n",
    "    residual   = varstore['residual']\n",
    "    aveR_ind   = varstore['aveR_ind']\n",
    "    M_N        = varstore['M_N']\n",
    "    factor_est = varstore['factor_est']\n",
    "    X          = varstore['X']\n",
    "    alpha2     = varstore['alpha2']\n",
    "    \n",
    "    alpha_boot = np.zeros([N, size])\n",
    "  \n",
    "    for b in range(size):\n",
    "       \n",
    "    # generate wild bootstrap data\n",
    "       \n",
    "        Weight = randn(N,T)/sqrt(2) + (randn(N,T)**2-1)/2\n",
    "        \n",
    "        U_boot = residual * Weight\n",
    "        \n",
    "        F_boot = factor_est\n",
    "        \n",
    "        X_boot = X\n",
    "              \n",
    "        R_boot = (beta_est @ lambda_est @ np.ones([1,T]) + beta_est @ F_boot + U_boot) * X_boot  # bootstrap return \n",
    "    \n",
    "        aveR_ind_boot = (np.sum(R_boot, axis = 1) / np.sum(X_boot,axis = 1)).reshape(-1,1)\n",
    "        \n",
    "        Rbar_boot     =  R_boot -  aveR_ind_boot @ np.ones([1,T])\n",
    "      \n",
    "       \n",
    "       #  OLS   \n",
    "        \n",
    "        beta_boot= np.zeros([N,K])\n",
    "       \n",
    "        for i in range(N):\n",
    "            \n",
    "            index = np.argwhere(X_boot[i,:]>0)\n",
    "            \n",
    "            d     = np.sum(X_boot[i,:])\n",
    "            \n",
    "            M_xi  = np.eye(d) - np.ones([d,d])/d\n",
    "            \n",
    "            factor= F_boot[:,index.flatten()]\n",
    "            \n",
    "            beta_boot[i,:]= R_boot[i,index.flatten()] @ M_xi @ factor.T @ inv(factor @ M_xi @ factor.T) \n",
    "             \n",
    "        # bootstrap alpha\n",
    "                \n",
    "        Pbeta_boot = lstsq((beta_boot.T @ M_N @ beta_boot), (beta_boot.T))[0] @ M_N \n",
    "            \n",
    "        lambda_boot =  Pbeta_boot @ aveR_ind_boot \n",
    "          \n",
    "        B_boot  = np.eye(N) - beta_boot @ Pbeta_boot  # needed for debias alpha\n",
    "            \n",
    "        g_boot  = np.zeros([N,1]) # needed for debias alpha    \n",
    "            \n",
    "        for i in range(N):\n",
    "                \n",
    "            g_boot[i] = beta_boot[i,:] @ np.mean(F_boot[:,X_boot[i,:]==1],axis=1).reshape(-1,1)\n",
    "           \n",
    "        alpha_boot[:,b] = (aveR_ind_boot - beta_boot @ lambda_boot - B_boot @ g_boot).flatten()\n",
    "   \n",
    "   \n",
    "    p  =  (1 + np.sum(alpha_boot > repmat(alpha2,1,size),axis=1))/(size + 1) # 1-normcdf(new_t); p-value\n",
    "    \n",
    "    p  = p.reshape(-1,1)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the func for matrix completion\n",
    "\n",
    "def matrix_completion (Z, X, K, sigmau):\n",
    "    \n",
    "    '''\n",
    "    This function is to do matrix completion\n",
    "    Assumption: Z = loadings * F + error\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "        Z        : return with missing data, N by T\n",
    "        X        : indicator of missing returns, observed = 1, N by T (omega in paper)\n",
    "        K        : number of factors\n",
    "        sigmau   : error variances, N by 1\n",
    "        \n",
    "    Output:\n",
    "    \n",
    "        F        : estimated factors, K by T\n",
    "        loadings : estimated loadings, N by K\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    [N, T]    = Z.shape\n",
    "    \n",
    "    stepwise  = 0.9 # between 0 and 1, closed to 1\n",
    "    \n",
    "    noise     = diag(sqrt(sigmau).flatten()) @ randn(N, T)\n",
    "    \n",
    "    tuning    = norm(noise*X, 2) *2.2\n",
    "    \n",
    "    threshold = stepwise*tuning/2\n",
    "    \n",
    "    # initial setting\n",
    "    \n",
    "    M         = Z\n",
    "    diff      = 10\n",
    "    \n",
    "    while diff > 1e-9:\n",
    "        \n",
    "        M_old            = M\n",
    "        \n",
    "        A                = M - X*(X*M-Z)*stepwise \n",
    "        \n",
    "        # % As the eig package in numpy does not guarantee the descending order, ordering manually\n",
    "        \n",
    "        [Stemp, Vtemp]   = eig (A.T @ A)\n",
    "        \n",
    "        S1               = sort(Stemp)[::-1][:K*2]\n",
    "        \n",
    "        V1               = np.zeros([(A.T @ A).shape[0],K*2])\n",
    "        \n",
    "        for i, eigen in enumerate(S1):\n",
    "            \n",
    "            V1[:, i]   =  Vtemp[:, list(Stemp).index(eigen)]\n",
    "            \n",
    "        \n",
    "        D1               = sqrt(diag(S1)) # get singular value\n",
    "        \n",
    "        U1               = A @ V1 @ inv(D1) \n",
    "        \n",
    "        D1new            = (D1-threshold) * (D1>threshold)\n",
    "        \n",
    "        M                = U1 @ D1new @ V1.T  # M = UDV\n",
    "        \n",
    "        diff             = norm(M-M_old)/sqrt(N*T)\n",
    "        \n",
    "        \n",
    "    Lambda   = U1[:,:K] * sqrt(N) # b1,...bK\n",
    "    \n",
    "    # factors\n",
    "    \n",
    "    F        = np.zeros([K, T])\n",
    "    \n",
    "    for t in range(T):\n",
    "        \n",
    "        F[:,t]           = lstsq((Lambda.T @ diag(X[:,t]) @ Lambda),\n",
    "                                  Lambda.T @ diag(X[:,t]) @ Z[:,t].reshape(-1,1))[0].reshape(1,-1).flatten() \n",
    "    # loadings\n",
    "    \n",
    "    loadings = np.zeros([N, K])\n",
    "\n",
    "    for i in range(N):\n",
    "        \n",
    "        loadings[i,:]    = (Z[i,:] @ diag(X[i,:]) @ F.T) @ inv(F @ diag(X[i,:]) @ F.T)\n",
    "        \n",
    "    return loadings, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function for B-H procedure\n",
    "\n",
    "def BH_procedure(p, N, T, tau):\n",
    "    \n",
    "    '''\n",
    "    This function is to run B-H procedure, with and without alpha screening\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "        p      : a series of p values, N by 1\n",
    "        N      : number of funds simulated\n",
    "        T      : number of time points\n",
    "        tau    : the given significance level in func-estimation\n",
    "        \n",
    "    Output:\n",
    "    \n",
    "        testB  : test results after BH, N by 1\n",
    "        testBH : test results after BH and alpha screening, N by 1\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # normal BH\n",
    "    \n",
    "    testB           = np.zeros([N, 1])\n",
    "        \n",
    "    index           = np.array(range(N)).reshape(-1,1)\n",
    "        \n",
    "    p_sort          = sort(p, axis = 0)\n",
    "    \n",
    "    k_hat           = max((p_sort <= index * tau / N) * index)[0]\n",
    "    \n",
    "    if k_hat>0:  # there are reject\n",
    "        \n",
    "        rejec_index                = index[p <= p_sort[k_hat]]        \n",
    "        \n",
    "        testB[rejec_index]         = 1\n",
    "\n",
    "    # BH with alpha screening    \n",
    "        \n",
    "    testBH          = np.zeros([N,1]) \n",
    "    \n",
    "    a1              = 1 - stats.norm.cdf(-log(log(T))*sqrt(log(N))/3)  \n",
    "    \n",
    "    screening_index = index[p <= a1] \n",
    "       \n",
    "    p_sort_screen   = sort(p[screening_index],axis = 0)\n",
    "    \n",
    "    N_screen        = len(p_sort_screen)\n",
    "    \n",
    "    index1          = np.array(range(N_screen)).reshape(-1,1)\n",
    "    \n",
    "    k_hat_screen    = max((p_sort_screen <= index1 * tau / N_screen) * index1)[0]\n",
    "        \n",
    "    if k_hat_screen > 0:  # there are reject\n",
    "    \n",
    "        b1                         = p_sort_screen[k_hat_screen]\n",
    "        \n",
    "        rejec_index_screen         = index[p <= min(a1,b1)]    \n",
    "        \n",
    "        testBH[rejec_index_screen] = 1\n",
    "   \n",
    "    return testB, testBH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the func for FDP and FDN\n",
    "\n",
    "def calculate_FDP_FDN (test_rej, alphatr):\n",
    "\n",
    "    '''\n",
    "    This function is to calculate FDP and FDN\n",
    "    \n",
    "    Input:\n",
    "\n",
    "        test_rej : indicator of those rejected tests, reject=1, N by 1\n",
    "        alphatr  : corresponding alphas, N by 1\n",
    "\n",
    "    Output:\n",
    "\n",
    "        FDP      : false reject portion\n",
    "        FDN      : false accept portion\n",
    "    '''\n",
    "\n",
    "    # calc FDP\n",
    "    \n",
    "    num_rej        = test_rej.sum()\n",
    "    \n",
    "    num_false_rej  = (test_rej*(alphatr<=0)).sum()\n",
    "\n",
    "    if num_rej>0:\n",
    "        \n",
    "        FDP        = num_false_rej/num_rej\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        FDP        = 0 # no reject\n",
    "\n",
    "    # calc FDN\n",
    "\n",
    "    num_accept     = len(test_rej) - num_rej\n",
    "    \n",
    "    num_false_acpt = ((1-test_rej)*(alphatr>0)).sum()\n",
    "\n",
    "    FDN            = num_false_acpt/num_accept\n",
    "    \n",
    "    # calc aver power\n",
    "    \n",
    "    num_true_rej   = num_rej - num_false_rej\n",
    "    \n",
    "    aver_power     = num_true_rej / np.sum(alphatr>0)\n",
    "\n",
    "    return FDP, FDN, aver_power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pkl form input and leave only used params\n",
    "# if just use pkl afterwards, igore this code cell\n",
    "\n",
    "mat_input   = loadmat('hfparams.mat')\n",
    "\n",
    "remain_vars = ['missing_patterns', 'factorscov', 'Ustd', 'beta', 'meanfacret', 'alpha']\n",
    "\n",
    "mat_extract = {}\n",
    "\n",
    "for v in remain_vars:\n",
    "    \n",
    "    mat_extract[v] = mat_input[v]\n",
    "    \n",
    "file = open('hfparams.pkl', 'wb')\n",
    "\n",
    "pickle.dump(mat_extract, file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently runing MC # 2\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d4d213b458f6>\u001b[0m in \u001b[0;36mmain_simulation_MC\u001b[0;34m(p1, p2, N, T)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# case (g) mixed 4 + 1 (with missing data + bootstrap) - see next notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mtest_B6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_BH6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_B6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_est_B6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_mis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSigma_uhat_mis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d8ee4cfc1349>\u001b[0m in \u001b[0;36mestimations\u001b[0;34m(R_obs, Fo, Kl, sigmau, tau, boot, bootsize)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mvardict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvarname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvarname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvardict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b0c1132efeab>\u001b[0m in \u001b[0;36mbootstrap\u001b[0;34m(varstore, size)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mF_boot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mbeta_boot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mR_boot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mM_xi\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mM_xi\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# bootstrap alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result0101=main_simulation_MC(0.1,0.1,1000,240)\n",
    "\n",
    "# write output to a pkl file\n",
    "\n",
    "file = open('py_Results_p1_'+str(result0101['p1'])+'_p2_'+\n",
    "            str(result0101['p2'])+'_N_'+str(result0101['N'])+\n",
    "            '_T_'+str(result0101['T'])+'_MC_boot.pkl', 'wb')\n",
    "pickle.dump(result0101, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# p1 = 0.1, p2 = 0.2\n",
    "\n",
    "result_0102 = main_simulation_MC(0.1,0.2,1000,240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_0102' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-305d5f14ff1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# retrieve the result from bootstrap for p1,p2 = 0.1, 0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult0101\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_0102\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result_0102' is not defined"
     ]
    }
   ],
   "source": [
    "### report FDP/aver power/FDN\n",
    "\n",
    "### append the bootstrap result to the result table\n",
    "\n",
    "result_list = [result0101boot]\n",
    "\n",
    "for result in result_list:\n",
    "\n",
    "    print ('FDP %,   ', round(np.mean(result['FDP_BH6'])*100, 2))\n",
    "\n",
    "    print ('FDP std,  ', round(std(result['FDP_BH6'])*100, 2))\n",
    "\n",
    "    print ('Average power %, ', round(np.mean(result['ave_pow_BH6'])*100, 2))\n",
    "\n",
    "    print ('FDN %,   ', round(np.mean(result['FDN_BH6'])*100, 2))\n",
    "\n",
    "    print ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
